cat("p-value (outcome 1):", pval1)
T_dist_2 <- replicate(K, FRT(y2[mask], Z_1[mask]))
cat("p-value (alternative outcome):", pval2)
T_dist_2 <- replicate(K, FRT(y2[mask], Z_1[mask]))
pval2 <- mean(T_dist_2 < -res2$tau_10 | T_dist_2 > res2$tau_10)
cat("p-value (alternative outcome):", pval2)
T_dist_1 <- replicate(K, FRT(y1[mask], Z_1[mask]))
pval1 <- mean(T_dist_1 < -res1$tau_10 | T_dist_1 > res1$tau_10)
cat("p-value (outcome 1):", pval1)
T_dist_2 <- replicate(K, FRT(y2[mask], Z_1[mask]))
pval2 <- mean(T_dist_2 < -res2$tau_10 | T_dist_2 > res2$tau_10)
cat("p-value (alternative outcome):", pval2)
T_dist_1 <- replicate(K, FRT(y1[mask], Z_1[mask]))
pval1 <- mean(T_dist_1 < -res1$tau_10 | T_dist_1 > res1$tau_10)
cat("p-value (outcome 1):", pval1)
T_dist_2 <- replicate(K, FRT(y2[mask], Z_1[mask]))
pval2 <- mean(T_dist_2 < -res2$tau_10 | T_dist_2 > res2$tau_10)
cat("p-value (alternative outcome):", pval2)
knitr::opts_chunk$set(include=T, warning=F, message=F)
set.seed(1234)
path <- "/Users/davidegiovanardi/Desktop/MSE327/HW1/"
setwd(path)
load(file='vernby.Rdata')
# Store data in vectors
y <- vernby$invited
Z <- vernby$citizen
W <- vernby$woman
N_11 <- sum(Z & W)
N_10 <- sum(Z & (1 - W))
N_01 <- sum((1 - Z) & W)
N_00 <- sum((1 - Z) & (1 - W))
# Check that the sum is correct
length(y) == N_11 + N_00 + N_10 + N_01
tau_hat <- (1/N_11 * sum(as.vector(Z & W) * y) -
1/N_10 * sum(as.vector(Z & (1-W)) * y))
compute_var <- function(Z, N, y) {
y_bar <- sum(Z * y) / N
var_Z <- 1/(N-1) * sum((Z * (y-y_bar)^2))
return(var_Z)
}
compute_CI <- function(tau, V, alpha=0.05) {
low <- tau - qnorm(1-alpha/2) * sqrt(V)
high <- tau + qnorm(1-alpha/2) * sqrt(V)
return(c(low, high))
}
V_11 <- compute_var(as.vector(Z & W), N_11, y)
V_10 <- compute_var(as.vector(Z & (1-W)), N_10, y)
V_hat <- V_11/N_11 + V_10/N_10
CI <- compute_CI(tau_hat, V_hat)
cat("TAU:\n",
"Difference in means estimator:", tau_hat, "\n",
"Conservative variance estimator:", V_hat, "\n",
"Confidence interval:", CI)
theta_hat <- (1/N_10 * sum(as.vector(Z & (1-W)) * y) -
1/N_00 * sum(as.vector((1-Z) & (1-W)) * y))
V_00 <- compute_var(as.vector((1-Z) & (1-W)), N_00, y)
V_hat <- V_00/N_00 + V_10/N_10
CI <- compute_CI(theta_hat, V_hat)
cat("THETA:\n",
"Difference in means estimator:", theta_hat, "\n",
"Conservative variance estimator:", V_hat, "\n",
"Confidence interval:", CI)
K <- 1000
FRT <- function() {
Z_k <- sample(Z)
W_k <- sample(W)
tau_k <- (1/N_11 * sum(as.vector(Z_k & W_k) * y) -
1/N_00 * sum(as.vector((1-Z_k) & (1-W_k)) * y))
return(tau_k)
}
T_dist <- replicate(K, FRT())
pval <- mean(T_dist > tau_hat | T_dist < -tau_hat)
cat("pvalue for the null hypothesis:", pval)
K <- 1000
FRT <- function() {
Z_k <- sample(Z)
W_k <- sample(W)
tau_k <- (1/N_11 * sum(as.vector(Z_k & W_k) * y) -
1/N_00 * sum(as.vector((1-Z_k) & (1-W_k)) * y))
return(tau_k)
}
gamma_hat <- (1/N_11 * sum(as.vector(Z & W) * y) -
1/N_00 * sum(as.vector((1-Z_k) & (1-W_k)) * y))
K <- 1000
FRT <- function() {
Z_k <- sample(Z)
W_k <- sample(W)
tau_k <- (1/N_11 * sum(as.vector(Z_k & W_k) * y) -
1/N_00 * sum(as.vector((1-Z_k) & (1-W_k)) * y))
return(tau_k)
}
gamma_hat <- (1/N_11 * sum(as.vector(Z & W) * y) -
1/N_00 * sum(as.vector((1-Z) & (1-W)) * y))
T_dist <- replicate(K, FRT())
pval <- mean(T_dist > gamma_hat | T_dist < -gamma_hat)
cat("pvalue for the null hypothesis:", pval)
gamma_aht
gamma_hat
knitr::opts_chunk$set(include=T, warning=F, message=F)
set.seed(1234)
path <- "/Users/davidegiovanardi/Desktop/MSE327/HW1/"
setwd(path)
load(file='vernby.Rdata')
# Store data in vectors
y <- vernby$invited
Z <- vernby$citizen
W <- vernby$woman
N_11 <- sum(Z & W)
N_10 <- sum(Z & (1 - W))
N_01 <- sum((1 - Z) & W)
N_00 <- sum((1 - Z) & (1 - W))
# Check that the sum is correct
length(y) == N_11 + N_00 + N_10 + N_01
tau_hat <- (1/N_11 * sum(as.vector(Z & W) * y) -
1/N_10 * sum(as.vector(Z & (1-W)) * y))
compute_var <- function(Z, N, y) {
y_bar <- sum(Z * y) / N
var_Z <- 1/(N-1) * sum((Z * (y-y_bar)^2))
return(var_Z)
}
compute_CI <- function(tau, V, alpha=0.05) {
low <- tau - qnorm(1-alpha/2) * sqrt(V)
high <- tau + qnorm(1-alpha/2) * sqrt(V)
return(c(low, high))
}
V_11 <- compute_var(as.vector(Z & W), N_11, y)
V_10 <- compute_var(as.vector(Z & (1-W)), N_10, y)
V_hat <- V_11/N_11 + V_10/N_10
CI <- compute_CI(tau_hat, V_hat)
cat("TAU:\n",
"Difference in means estimator:", tau_hat, "\n",
"Conservative variance estimator:", V_hat, "\n",
"Confidence interval:", CI)
theta_hat <- (1/N_10 * sum(as.vector(Z & (1-W)) * y) -
1/N_00 * sum(as.vector((1-Z) & (1-W)) * y))
V_00 <- compute_var(as.vector((1-Z) & (1-W)), N_00, y)
V_hat <- V_00/N_00 + V_10/N_10
CI <- compute_CI(theta_hat, V_hat)
cat("THETA:\n",
"Difference in means estimator:", theta_hat, "\n",
"Conservative variance estimator:", V_hat, "\n",
"Confidence interval:", CI)
K <- 1000
FRT <- function() {
Z_k <- sample(Z)
W_k <- sample(W)
tau_k <- (1/N_11 * sum(as.vector(Z_k & W_k) * y) -
1/N_00 * sum(as.vector((1-Z_k) & (1-W_k)) * y))
return(tau_k)
}
gamma_hat <- (1/N_11 * sum(as.vector(Z & W) * y) -
1/N_00 * sum(as.vector((1-Z) & (1-W)) * y))
T_dist <- replicate(K, FRT())
pval <- mean(T_dist > gamma_hat | T_dist < -gamma_hat)
cat("pvalue for the null hypothesis:", pval)
gamma_hat
knitr::opts_chunk$set(include=T, warning=F, message=F)
set.seed(1234)
N_1 <- seq(0,N,1)
seq(0,10)
N_1 <- seq(0,N)
N <- 180
N_1 <- seq(0,N)
N <- 180
N_1 <- seq(0,N)
pi_01 <- N_1 * (N - N_1) / N^2
pi_00 <- (1 - N_1)^2 / N^2
plot(N_1, pi_01)
points(N_1, pi_00)
pi_00 <- (N - N_1)^2 / N^2
plot(N_1, pi_01)
points(N_1, pi_00)
knitr::opts_chunk$set(include=T, warning=F, message=F)
require(ggplot2)
set.seed(1234)
ggplot(df, aes(x = N_1)) +
geom_line(aes(y = pi_01)) +
geom_line(aes(y = pi_00))
df <- data.frame(cbind(pi_01, pi_00))
ggplot(df, aes(x = N_1)) +
geom_line(aes(y = pi_01)) +
geom_line(aes(y = pi_00))
df <- data.frame(cbind(pi_01 = pi_01,
pi_00 = pi_00))
ggplot(df, aes(x = N_1)) +
geom_line(aes(y = pi_01)) +
geom_line(aes(y = pi_00)) +
theme_minimal() +
xlab("N_1") +
ylab("Probability") +
ggtitle("Problem 1 - Part A.2")
ggplot(df, aes(x = N_1)) +
geom_line(aes(y = pi_01)) +
geom_line(aes(y = pi_00)) +
theme_minimal() +
xlab("N_1") +
ylab("Probability") +
ggtitle("Problem 1 - Part A.2") +
legend()
df <- data.frame(cbind(pi_01 = pi_01,
pi_00 = pi_00))
ggplot(df, aes(x = N_1)) +
geom_line(aes(y = pi_01)) +
geom_line(aes(y = pi_00)) +
theme_minimal() +
xlab("N_1") +
ylab("Probability") +
ggtitle("Problem 1 - Part A.2") +
legend()
ggplot(df, aes(x = N_1)) +
geom_line(aes(y = pi_01)) +
geom_line(aes(y = pi_00)) +
theme_minimal() +
xlab("N_1") +
ylab("Probability") +
ggtitle("Problem 1 - Part A.2")
ggplot(df, aes(x = N_1)) +
geom_line(aes(y = pi_01), c='red') +
geom_line(aes(y = pi_00)) +
theme_minimal() +
xlab("N_1") +
ylab("Probability") +
ggtitle("Problem 1 - Part A.2")
ggplot(df, aes(x = N_1)) +
geom_line(aes(y = pi_01), colour='red') +
geom_line(aes(y = pi_00)) +
theme_minimal() +
xlab("N_1") +
ylab("Probability") +
ggtitle("Problem 1 - Part A.2")
ggplot(df, aes(x = N_1)) +
geom_line(aes(y = pi_01), colour='red') +
geom_line(aes(y = pi_00), colour='blue') +
theme_minimal() +
xlab("N_1") +
ylab("Probability") +
ggtitle("Problem 1 - Part A.2") +
theme(legend.position="right")
ggplot(df, aes(x = N_1)) +
geom_line(aes(y = pi_01), colour='red') +
geom_line(aes(y = pi_00), colour='blue') +
theme_minimal() +
xlab("N_1") +
ylab("Probability") +
ggtitle("Problem 1 - Part A.2") +
theme(legend.position="center")
ggplot(df, aes(x = N_1)) +
geom_line(aes(y = pi_01), colour='red') +
geom_line(aes(y = pi_00), colour='blue') +
theme_minimal() +
xlab("N_1") +
ylab("Probability") +
ggtitle("Problem 1 - Part A.2")
knitr::opts_chunk$set(include=T, warning=F, message=F)
require(ggplot2)
set.seed(1234)
N <- 180
N_1 <- seq(0,N)
pi_01 <- N_1 * (N - N_1) / N*(N-1)
pi_00 <- (N - N_1)^2 / N*(N-1)
df <- data.frame(cbind(pi_01 = pi_01,
pi_00 = pi_00))
ggplot(df, aes(x = N_1)) +
geom_line(aes(y = pi_01), colour='red') +
geom_line(aes(y = pi_00), colour='blue') +
theme_minimal() +
xlab("N_1") +
ylab("Probability") +
ggtitle("Problem 1 - Part A.2")
knitr::opts_chunk$set(echo = TRUE)
diabetes=readRDS("diabetes.rds")
View(diabetes)
diabetes$x
diabetes$x2
nrow(diabetes$x)
identity(n)
diag(0.2, n)
diag(0.2, 10)
fit <- function(X, y, lamb) {
n = nrow(X)
beta <- solve(t(X) %*% X + diag(lamb, n)) %*% t(X) %*% y
return(beta)
}
CV <- function(X, y, k=10) {
set.seed(10)
n = nrow(X)
perm = sample(n)
X = as.matrix(X[perm,])
y = as.matrix(y[perm])
test_size = floor(n/k)
for (i in 0:(k-1)) {
# select test fold
test_idx = (i*test_size+1):((i+1)*test_size)
# create folds
X_train = X[-test_idx,]
X_test = X[test_idx,]
y_train = y[-test_idx]
y_test = y[test_idx]
}
}
sd(diabetes$x)
diabetes$x
apply(diabetes$x, 2, sd)
as.vector(apply(diabetes$x, 2, sd))
diag(sigma)
diag(as.vector(apply(diabetes$x, 2, sd)))
standardize <- function(X) {
sigma <- as.vector(apply(diabetes$x, 2, sd))
D <- diag(sigma)
return(X %*% D)
}
X_tilde <- standardize(diabetes$x)
fit(X_tilde, diabetes$y)
fit(X_tilde, diabetes$y, 0.4)
dim(t(X_tilde) %*% X_tilde)
fit <- function(X, y, lamb) {
p = ncol(X)
beta <- solve(t(X) %*% X + diag(lamb, p)) %*% t(X) %*% y
return(beta)
}
fit(X_tilde, diabetes$y, 0.4)
diag(2, 3)
D = diag(2, 3)
D[0,0] = 0
D
D[1,1] = 0
D
fit <- function(X, y, lamb) {
n = nrows(X)
X = cbind(rep(1,n), X)
p = ncol(X)
D = diag(lamb, p)
D[1,1] = 0
beta <- solve(t(X) %*% X + D) %*% t(X) %*% y
return(beta)
}
fit(X_tilde, diabetes$y, 0.4)
fit <- function(X, y, lamb) {
n = nrow(X)
X = cbind(rep(1,n), X)
p = ncol(X)
D = diag(lamb, p)
D[1,1] = 0
beta <- solve(t(X) %*% X + D) %*% t(X) %*% y
return(beta)
}
fit(X_tilde, diabetes$y, 0.4)
standardize <- function(X) {
sigma <- as.vector(apply(diabetes$x, 2, sd))
D <- diag(sigma)
return(X %*% D)
}
fit <- function(X, y, lamb) {
n = nrow(X)
X = cbind(rep(1,n), X)
p = ncol(X)
D = diag(lamb, p)
# D[1,1] = 0
beta <- solve(t(X) %*% X + D) %*% t(X) %*% y
return(beta)
}
standardize <- function(X) {
sigma <- as.vector(apply(diabetes$x, 2, sd))
D <- diag(sigma)
return(X %*% D)
}
X_tilde <- standardize(diabetes$x)
fit(X_tilde, diabetes$y, 0.4)
fit <- function(X, y, lamb) {
n = nrow(X)
X = cbind(rep(1,n), X)
p = ncol(X)
D = diag(lamb, p)
D[1,1] = 0
beta <- solve(t(X) %*% X + D) %*% t(X) %*% y
return(beta)
}
diabetes$y
fit(X_tilde, diabetes$y, 0.4)
library(glmnet)
install.packages("glmnet")
library(glmnet)
fit <- glmnet(X_tilde, diabetes$y, alpha = 0, lambda = 0.4)
summary(fit)
fit.coefficients
fit.coefs
fit_ridge <- function(X, y, lamb) {
n = nrow(X)
X = cbind(rep(1,n), X)
p = ncol(X)
D = diag(lamb, p)
D[1,1] = 0
beta <- solve(t(X) %*% X + D) %*% t(X) %*% y
return(beta)
}
standardize <- function(X) {
sigma <- as.vector(apply(diabetes$x, 2, sd))
D <- diag(sigma)
return(X %*% D)
}
X_tilde <- standardize(diabetes$x)
fit_ridge(X_tilde, diabetes$y, 0.4)
fit <- glmnet(X_tilde, diabetes$y, alpha = 0, lambda = 0.4)
fit
View(fit)
fit.beta
fit$beta
fit_ridge(X_tilde, diabetes$y, 0.9)
fit <- glmnet(X_tilde, diabetes$y, alpha = 0, lambda = 0.9)
fit$beta
n = nrow(X_tilde)
X_tilde = cbind(rep(1,n), X_tilde)
fit <- glmnet(X_tilde, diabetes$y, alpha = 0, lambda = 0.9)
fit$beta
fit <- glmnet(X_tilde, diabetes$y, alpha = 0)
fit$beta
View(fit)
X_tilde <- standardize(diabetes$x)
fit_ridge(X_tilde, diabetes$y, 0.9)
fit <- glmnet(X_tilde, diabetes$y, alpha = 0)
fit$beta
fit <- glmnet(X_tilde, diabetes$y, alpha = 0, lambda=0.9)
fit$beta
fit$a0
fit_ridge(X_tilde, diabetes$y, 0.9)
lm(diabetes$y ~ X_tilde)
X = X_tilde
solve(t(X) %*% X) %*% t(X) %*% y
solve(t(X) %*% X) %*% t(X) %*% diabetes$y
solve(t(X) %*% X + diag(0.9)) %*% t(X) %*% diabetes$y
solve(t(X) %*% X + diag(0.9, ncol(X))) %*% t(X) %*% diabetes$y
inv(t(X) %*% X + diag(0.9, ncol(X))) %*% t(X) %*% diabetes$y
solve(t(X) %*% X + diag(0.9, ncol(X)), %*% t(X) %*% diabetes$y)
solve(t(X) %*% X + diag(0.9, ncol(X)), t(X) %*% diabetes$y)
library (ridge)
install.packages("ridge")
library (ridge)
lm(diabetes$y ~ X_tilde)
fit <- linearRidge(diabetes$y ~ X_tilde)
fit$coef
fit <- lm.ridge(diabetes$y ~ X_tilde)
fit_ridge(X_tilde, diabetes$y, 0.9)
fit <- linearRidge(diabetes$y ~ X_tilde, lambda = 0.9, nPCs = NULL)
fit$coef
fit_ridge(X_tilde, diabetes$y, 0.9)
X_tilde <- standardize(diabetes$x)
fit_ridge(X_tilde, diabetes$y, 0.9)
fit$a0
fit <- glmnet(X_tilde, diabetes$y, alpha = 0, lambda=0.9)
fit$beta
fit <- glmnet(X_tilde, diabetes$y, alpha = 0, lambda=9)
fit$beta
fit <- glmnet(X_tilde, diabetes$y, alpha = 0, lambda=100)
fit$beta
fit$a0
fit <- glmnet(X, diabetes$y, alpha = 0, lambda=100)
fit$beta
# install.packages("devtools")
library(devtools)
# Download package tarball from CRAN archive
url <- "https://cran.r-project.org/src/contrib/Archive/zipcode/zipcode_1.0.tar.gz"
pkgFile <- "zipcode_1.0.tar.gz"
download.file(url = url, destfile = pkgFile)
# Install package
install.packages(pkgs=pkgFile, type="source", repos=NULL)
# Delete package tarball
unlink(pkgFile)
devtools::install_github("czigler/arepa")
rm(list=ls())
library(zipcode)
library(arepa)
datdir_in = "Other Data Files/"
## ---------------------------------------------------------------------------------------- ##
##   Step 1: Download AQS data, and link zip codes to monitoring locations                  ##
## ---------------------------------------------------------------------------------------- ##
years = 1990:2013
parameter_code = 88101 # for PM 2.5
within_km = 9.656 # 6 miles  ### 4.828 #3 miles #####
observation_percent = 67
aqsdat = load_annual_average(years)  ## only load the data that you'll use for the main analysis
setwd('/Users/davidegiovanardi/Downloads/PM2.5-Nonattainment/Data\ Construction')
aqsdat = load_annual_average(years)  ## only load the data that you'll use for the main analysis
aqsdat = load_annual_average(years)  ## only load the data that you'll use for the main analysis
##--   Get annual PM10 AQS data from EPA
#-- Downloaded on 7/6/2015 - don't download again unless you're prepared to absorb changes to the raw data (which should be minor)
get_AQS_data_annual(1990:2013)  ## get more years than you'll use for the main analysis.
aqsdat = load_annual_average(years)  ## only load the data that you'll use for the main analysis
PM = subset_monitors(MONITORS = aqsdat, parameter_code,
observation_percent = observation_percent,
monitor_info_file = paste(datdir_in, "/monitor_list.csv", sep = ""))
PM
## ---------------------------------------------------------------------------------------- ##
##   Step 1: Download AQS data, and link zip codes to monitoring locations                  ##
## ---------------------------------------------------------------------------------------- ##
years = 1990:2013
parameter_code = 88101 # for PM 2.5
within_km = 9.656 # 6 miles  ### 4.828 #3 miles #####
observation_percent = 67
PM = subset_monitors(MONITORS = aqsdat, parameter_code,
observation_percent = observation_percent,
monitor_info_file = paste(datdir_in, "/monitor_list.csv", sep = ""))
datdir_in = "Other Data Files/"
library(zipcode)
library(arepa)
##--   Get annual PM10 AQS data from EPA
#-- Downloaded on 7/6/2015 - don't download again unless you're prepared to absorb changes to the raw data (which should be minor)
get_AQS_data_annual(1990:2014)  ## get more years than you'll use for the main analysis.
aqsdat = load_annual_average(years)  ## only load the data that you'll use for the main analysis
aqsdat
PM = subset_monitors(MONITORS = aqsdat, parameter_code,
observation_percent = observation_percent,
monitor_info_file = paste(datdir_in, "/monitor_list.csv", sep = ""))
